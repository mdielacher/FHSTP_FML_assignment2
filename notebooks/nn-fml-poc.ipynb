{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 2.1.1 and Flower 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility\n",
    "seed_value = 42\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank_a = pd.read_csv('../data/BankA.csv')\n",
    "df_bank_b = pd.read_csv('../data/BankB.csv')\n",
    "df_bank_c = pd.read_csv('../data/BankC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_bank_a, df_bank_b, df_bank_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip all string values from the dataset\n",
    "df = df_all.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Never-worked and Without-pay into one category\n",
    "df['workclass'] = df['workclass'].replace(['Never-worked', 'Without-pay'], 'Not-working')\n",
    "df['workclass'] = df['workclass'].replace(['?', '*'], 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Married-civ-spouse and Married-AF-spouse into one category\n",
    "df['marital-status'] = df['marital-status'].replace(['Married-civ-spouse', 'Married-AF-spouse'], 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace occupation by 4 categories (low, medium, high, unknown)\n",
    "df['occupation'] = df['occupation'].replace(['Exec-managerial', 'Prof-specialty'], 'high')\n",
    "df['occupation'] = df['occupation'].replace(['Armed-Forces', 'Protective-serv', 'Tech-support', 'Sales', 'Craft-repair', 'Transport-moving'], 'medium')\n",
    "df['occupation'] = df['occupation'].replace(['Adm-clerical', 'Machine-op-inspct', 'Farming-fishing', 'Handlers-cleaners', 'Other-service', 'Priv-house-serv'], 'low')\n",
    "df['occupation'] = df['occupation'].replace(['?', '*'], 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Husband and Wife into one category\n",
    "df['relationship'] = df['relationship'].replace(['Husband', 'Wife'], 'Parent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map native-country to continents\n",
    "df['native-country'] = df['native-country'].str.strip()\n",
    "df['native-country'] = df['native-country'].replace(['United-States', 'Puerto-Rico', 'Canada', 'Outlying-US(Guam-USVI-etc)', 'Cuba', 'Jamaica', 'Mexico', 'Dominican-Republic', 'El-Salvador', 'Guatemala', 'Haiti', 'Honduras', 'Nicaragua', 'Trinadad&Tobago', 'Peru', 'Ecuador', 'Columbia', 'Honduras', 'Haiti', 'Guatemala', 'El-Salvador', 'Dominican-Republic', 'Columbia', 'Ecuador', 'Peru', 'Jamaica', 'Mexico', 'Puerto-Rico', 'Cuba', 'Outlying-US(Guam-USVI-etc)', 'Canada', 'United-States'], 'North-America')\n",
    "df['native-country'] = df['native-country'].replace(['Germany', 'England', 'Italy', 'Poland', 'Portugal', 'Ireland', 'France', 'Yugoslavia', 'Scotland', 'Greece', 'Hungary', 'Holand-Netherlands'], 'Europe')\n",
    "df['native-country'] = df['native-country'].replace(['Philippines', 'India', 'China', 'Japan', 'Vietnam', 'Taiwan', 'Iran', 'Thailand', 'Hong', 'Cambodia', 'Laos'], 'Asia')\n",
    "df['native-country'] = df['native-country'].replace(['South', 'Columbia', 'Ecuador', 'Peru'], 'South-America')\n",
    "df['native-country'] = df['native-country'].replace(['Trinadad&Tobago', 'Honduras', 'Haiti', 'Guatemala', 'El-Salvador', 'Dominican-Republic', 'Columbia', 'Ecuador', 'Peru'], 'Central-America')\n",
    "df['native-country'] = df['native-country'].replace(['?', '*'], 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'] = df['education'].replace(['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th'], 'school')\n",
    "df['education'] = df['education'].replace(['Assoc-voc', 'Assoc-acdm', 'Prof-school', 'Some-college'], 'higher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulate capital-diff\n",
    "df['capital-diff'] = df['capital-gain'] - df['capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace(['Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert age in bins of 10 years\n",
    "df['age'] = pd.cut(df['age'], bins=[0, 20, 30, 40, 50, 60, 70, 80, 90, 100], labels=['0-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '>90'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the fnlwgt column\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Drop education-num column\n",
    "df.drop(['educational-num'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the gender column\n",
    "df.drop(['gender'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the race column\n",
    "df.drop('race', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace income by 0 and 1\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: institute\n",
      "institute\n",
      "Bank B    403240\n",
      "Bank A    226164\n",
      "Bank C    170595\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: workclass\n",
      "workclass\n",
      "Private             546342\n",
      "Self-emp-not-inc     66145\n",
      "Local-gov            51137\n",
      "unknown              47431\n",
      "State-gov            34717\n",
      "Self-emp-inc         27715\n",
      "Federal-gov          25879\n",
      "Not-working            633\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: education\n",
      "education\n",
      "HS-grad      258661\n",
      "higher       241834\n",
      "Bachelors    133796\n",
      "school       110209\n",
      "Masters       45697\n",
      "Doctorate      9802\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: marital-status\n",
      "marital-status\n",
      "Married                  368820\n",
      "Never-married            250510\n",
      "Divorced                 110459\n",
      "Widowed                   34203\n",
      "Separated                 25566\n",
      "Married-spouse-absent     10441\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: occupation\n",
      "occupation\n",
      "low        281223\n",
      "medium     259651\n",
      "high       211330\n",
      "unknown     47795\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: relationship\n",
      "relationship\n",
      "Parent            362767\n",
      "Not-in-family     212898\n",
      "Own-child         119123\n",
      "Unmarried          80532\n",
      "Other-relative     24679\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: native-country\n",
      "native-country\n",
      "North-America    753935\n",
      "Asia              14694\n",
      "Unknown           14390\n",
      "Europe            14273\n",
      "South-America      2707\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-gain\n",
      "(-100.0, 16666.5]     792260\n",
      "(83332.5, 99999.0]      4665\n",
      "(16666.5, 33333.0]      3019\n",
      "(33333.0, 49999.5]        55\n",
      "(49999.5, 66666.0]         0\n",
      "(66666.0, 83332.5]         0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-loss\n",
      "(-3.6839999999999997, 613.833]    760671\n",
      "(1841.5, 2455.333]                 25034\n",
      "(1227.667, 1841.5]                 12776\n",
      "(2455.333, 3069.167]                 788\n",
      "(613.833, 1227.667]                  540\n",
      "(3069.167, 3683.0]                   190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: hours-per-week\n",
      "(33.667, 50.0]      555199\n",
      "(17.333, 33.667]    105827\n",
      "(50.0, 66.333]       72075\n",
      "(0.901, 17.333]      44806\n",
      "(66.333, 82.667]     16324\n",
      "(82.667, 99.0]        5768\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: income\n",
      "(-0.002, 0.167]    601449\n",
      "(0.833, 1.0]       198550\n",
      "(0.167, 0.333]          0\n",
      "(0.333, 0.5]            0\n",
      "(0.5, 0.667]            0\n",
      "(0.667, 0.833]          0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-diff\n",
      "(-3786.683, 13597.333]    783776\n",
      "(13597.333, 30877.667]     11477\n",
      "(82718.667, 99999.0]        4665\n",
      "(30877.667, 48158.0]          81\n",
      "(48158.0, 65438.333]           0\n",
      "(65438.333, 82718.667]         0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    " \n",
    "for column in df[categorical_columns].columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(df[column].value_counts())\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "# Print also the numberical columns, categorize them into bins of 6\n",
    "numerical_columns = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "for column in df[numerical_columns].columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(df[column].value_counts(bins=6))\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "categorical_columns = categorical_columns.append(pd.Index(['age']))\n",
    "df = pd.get_dummies(df, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop institutes columns\n",
    "df_all = df.drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_a = df[df['institute_Bank A'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_b = df[df['institute_Bank B'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_c = df[df['institute_Bank C'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_all:    799999\n",
      "Number of rows in df_bank_a: 226164\n",
      "Number of rows in df_bank_b: 403240\n",
      "Number of rows in df_bank_c: 170595\n"
     ]
    }
   ],
   "source": [
    "# number of rows in each dataset\n",
    "print(f\"Number of rows in df_all:    {len(df_all)}\")\n",
    "print(f\"Number of rows in df_bank_a: {len(df_bank_a)}\")\n",
    "print(f\"Number of rows in df_bank_b: {len(df_bank_b)}\")\n",
    "print(f\"Number of rows in df_bank_c: {len(df_bank_c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test set that contains 20% of the data from each bank\n",
    "df_bank_a_test = df_bank_a.sample(frac=0.2, random_state=42)\n",
    "df_bank_b_test = df_bank_b.sample(frac=0.2, random_state=42)\n",
    "df_bank_c_test = df_bank_c.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Create a training set that contains the remaining 80% of the data from each bank\n",
    "df_bank_a_train = df_bank_a.drop(df_bank_a_test.index)\n",
    "df_bank_b_train = df_bank_b.drop(df_bank_b_test.index)\n",
    "df_bank_c_train = df_bank_c.drop(df_bank_c_test.index)\n",
    "\n",
    "# Create a validation set that contains 20% of the data from each bank\n",
    "df_bank_a_val = df_bank_a_train.sample(frac=0.2, random_state=42)\n",
    "df_bank_b_val = df_bank_b_train.sample(frac=0.2, random_state=42)\n",
    "df_bank_c_val = df_bank_c_train.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Create a training set that contains the remaining 80% of the data from each bank\n",
    "df_bank_a_train = df_bank_a_train.drop(df_bank_a_val.index)\n",
    "df_bank_b_train = df_bank_b_train.drop(df_bank_b_val.index)\n",
    "df_bank_c_train = df_bank_c_train.drop(df_bank_c_val.index)\n",
    "\n",
    "# Combine the training sets into one training set\n",
    "df_train = pd.concat([df_bank_a_train, df_bank_b_train, df_bank_c_train])\n",
    "\n",
    "# Combine the test sets into one test set\n",
    "df_test = pd.concat([df_bank_a_test, df_bank_b_test, df_bank_c_test])\n",
    "\n",
    "# Combine the validation sets into one validation set\n",
    "df_val = pd.concat([df_bank_a_val, df_bank_b_val, df_bank_c_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and test sets into X and y\n",
    "X_train = df_train.drop('income', axis=1)\n",
    "y_train = df_train['income']\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test['income']\n",
    "X_val = df_val.drop('income', axis=1)\n",
    "y_val = df_val['income']\n",
    "\n",
    "X_train_bank_a = df_bank_a_train.drop('income', axis=1)\n",
    "y_train_bank_a = df_bank_a_train['income']\n",
    "X_test_bank_a = df_bank_a_test.drop('income', axis=1)\n",
    "y_test_bank_a = df_bank_a_test['income']\n",
    "\n",
    "X_train_bank_b = df_bank_b_train.drop('income', axis=1)\n",
    "y_train_bank_b = df_bank_b_train['income']\n",
    "X_test_bank_b = df_bank_b_test.drop('income', axis=1)\n",
    "y_test_bank_b = df_bank_b_test['income']\n",
    "\n",
    "X_train_bank_c = df_bank_c_train.drop('income', axis=1)\n",
    "y_train_bank_c = df_bank_c_train['income']\n",
    "X_test_bank_c = df_bank_c_test.drop('income', axis=1)\n",
    "y_test_bank_c = df_bank_c_test['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "X_val = np.asarray(X_val).astype(np.float32)\n",
    "y_val = np.asarray(y_val).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(5, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(16, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 2s 529us/step - loss: 0.5658 - accuracy: 0.7533 - val_loss: 0.5510 - val_accuracy: 0.7519\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 2s 504us/step - loss: 0.5553 - accuracy: 0.7543 - val_loss: 0.5506 - val_accuracy: 0.7534\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 2s 515us/step - loss: 0.5549 - accuracy: 0.7548 - val_loss: 0.5510 - val_accuracy: 0.7519\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 2s 500us/step - loss: 0.5550 - accuracy: 0.7545 - val_loss: 0.5505 - val_accuracy: 0.7521\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 2s 497us/step - loss: 0.5547 - accuracy: 0.7549 - val_loss: 0.5503 - val_accuracy: 0.7529\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 2s 501us/step - loss: 0.5547 - accuracy: 0.7553 - val_loss: 0.5510 - val_accuracy: 0.7519\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 2s 499us/step - loss: 0.5547 - accuracy: 0.7551 - val_loss: 0.5514 - val_accuracy: 0.7520\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 2s 503us/step - loss: 0.5543 - accuracy: 0.7552 - val_loss: 0.5501 - val_accuracy: 0.7519\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 2s 496us/step - loss: 0.5530 - accuracy: 0.7551 - val_loss: 0.5496 - val_accuracy: 0.7519\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 2s 495us/step - loss: 0.5494 - accuracy: 0.7548 - val_loss: 0.5411 - val_accuracy: 0.7520\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 2s 308us/step\n",
      "[[120488     31]\n",
      " [ 39474      7]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75309375"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FML Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 3 # Bank A, B, C\n",
    "NUM_FML_ROUNDS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"Constructs a simple model architecture suitable for the Dataset.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(128, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(40, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(40, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    tf.random.set_seed(seed_value)\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialClient(fl.client.NumPyClient):\n",
    "    def __init__(self, trainset, valset) -> None:\n",
    "        # Create model\n",
    "        self.model = get_model()\n",
    "        self.trainset = trainset\n",
    "        self.valset = valset\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        tf.random.set_seed(seed_value)\n",
    "        self.model.fit(self.trainset[0], self.trainset[1], epochs=1, batch_size=512, verbose=VERBOSE)\n",
    "        return self.model.get_weights(), len(self.trainset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, acc = self.model.evaluate(self.valset[0], self.valset[1], verbose=VERBOSE)\n",
    "        return loss, len(self.valset), {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_fn(global_train_datasets_list):\n",
    "    \"\"\"Return a function to construct a client.\n",
    "\n",
    "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
    "    the strategy to participate.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> fl.client.Client:\n",
    "        \"\"\"Construct a DiabetesClient with its own dataset partition.\"\"\"\n",
    "\n",
    "        # Extract partition for client with id = cid\n",
    "        X, y = global_train_datasets_list[int(cid)]\n",
    "\n",
    "        # Now let's split it into train (90%) and validation (10%)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=seed_value)\n",
    "\n",
    "        trainset = (X_train, y_train)\n",
    "        valset = (X_val, y_val)\n",
    "\n",
    "        # Create and return client\n",
    "        return FinancialClient(trainset, valset)\n",
    "\n",
    "    return client_fn\n",
    "\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
    "    the client's evaluate() method.\"\"\"\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "\n",
    "def get_evaluate_fn(testset):\n",
    "    \"\"\"Return an evaluation function for server-side (i.e. centralised) evaluation.\"\"\"\n",
    "\n",
    "    # The `evaluate` function will be called after every round by the strategy\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ):\n",
    "        model = get_model()  # Construct the model\n",
    "        model.set_weights(parameters)  # Update model with the latest parameters\n",
    "        loss, accuracy = model.evaluate(testset[0], testset[1], verbose=VERBOSE)\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comine train and validation sets for each bank\n",
    "df_bank_a_train_val = pd.concat([df_bank_a_train, df_bank_a_val])\n",
    "df_bank_b_train_val = pd.concat([df_bank_b_train, df_bank_b_val])\n",
    "df_bank_c_train_val = pd.concat([df_bank_c_train, df_bank_c_val])\n",
    "\n",
    "# Split data into X and y\n",
    "X_train_val_bank_a = df_bank_a_train_val.drop('income', axis=1)\n",
    "y_train_val_bank_a = df_bank_a_train_val['income']\n",
    "\n",
    "X_train_val_bank_b = df_bank_b_train_val.drop('income', axis=1)\n",
    "y_train_val_bank_b = df_bank_b_train_val['income']\n",
    "\n",
    "X_train_val_bank_c = df_bank_c_train_val.drop('income', axis=1)\n",
    "y_train_val_bank_c = df_bank_c_train_val['income']\n",
    "\n",
    "X_train_val_bank_a = np.asarray(X_train_val_bank_a).astype(np.float32)\n",
    "y_train_val_bank_a = np.asarray(y_train_val_bank_a).astype(np.float32)\n",
    "\n",
    "X_train_val_bank_b = np.asarray(X_train_val_bank_b).astype(np.float32)\n",
    "y_train_val_bank_b = np.asarray(y_train_val_bank_b).astype(np.float32)\n",
    "\n",
    "X_train_val_bank_c = np.asarray(X_train_val_bank_c).astype(np.float32)\n",
    "y_train_val_bank_c = np.asarray(y_train_val_bank_c).astype(np.float32)\n",
    "\n",
    "# Create a list of datasets for each bank\n",
    "global_train_datasets_list = [\n",
    "    (X_train_val_bank_a, y_train_val_bank_a),\n",
    "    (X_train_val_bank_b, y_train_val_bank_b),\n",
    "    (X_train_val_bank_c, y_train_val_bank_c),\n",
    "]\n",
    "\n",
    "# Create a test set\n",
    "df_test = pd.concat([df_bank_a_test, df_bank_b_test, df_bank_c_test])\n",
    "\n",
    "# Split data into X and y\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test['income']\n",
    "\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "global_test_dataset = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-02-01 11:07:24,000 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
      "2024-02-01 11:07:27,719\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-02-01 11:07:28,332 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 7761456333.0, 'object_store_memory': 2147483648.0, 'node:__internal_head__': 1.0, 'node:127.0.0.1': 1.0, 'CPU': 12.0}\n",
      "INFO flwr 2024-02-01 11:07:28,332 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "/var/folders/sk/8bkznljj6dzctmmh_hh2qcfh0000gn/T/ipykernel_13096/699290821.py:17: UserWarning: No `num_cpus` specified in `client_resources`. Using `num_cpus=1` for each client.\n",
      "  history_nn = fl.simulation.start_simulation(\n",
      "INFO flwr 2024-02-01 11:07:28,334 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_gpus': 0, 'num_cpus': 1}\n",
      "INFO flwr 2024-02-01 11:07:28,345 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 12 actors\n",
      "INFO flwr 2024-02-01 11:07:28,345 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-02-01 11:07:28,345 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-02-01 11:07:33,204 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-02-01 11:07:33,205 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-02-01 11:07:34,892 | server.py:94 | initial parameters (loss, other metrics): 198.40919494628906, {'accuracy': 0.7532437443733215}\n",
      "INFO flwr 2024-02-01 11:07:34,892 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-02-01 11:07:34,893 | server.py:222 | fit_round 1: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:36,718 | server.py:236 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2024-02-01 11:07:36,720 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "INFO flwr 2024-02-01 11:07:38,358 | server.py:125 | fit progress: (1, 0.642350435256958, {'accuracy': 0.7923937439918518}, 3.4652488749707118)\n",
      "DEBUG flwr 2024-02-01 11:07:38,358 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:39,190 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:07:39,191 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:40,610 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:07:42,254 | server.py:125 | fit progress: (2, 0.37901946902275085, {'accuracy': 0.788100004196167}, 7.361226707929745)\n",
      "DEBUG flwr 2024-02-01 11:07:42,254 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:43,162 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:07:43,162 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:44,574 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:07:46,223 | server.py:125 | fit progress: (3, 0.3761957883834839, {'accuracy': 0.8126687407493591}, 11.330906249932013)\n",
      "DEBUG flwr 2024-02-01 11:07:46,224 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:46,753 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:07:46,753 | server.py:222 | fit_round 4: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:50,392 | server.py:236 | fit_round 4 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:07:52,064 | server.py:125 | fit progress: (4, 0.37506216764450073, {'accuracy': 0.8127187490463257}, 17.171814291970804)\n",
      "DEBUG flwr 2024-02-01 11:07:52,065 | server.py:173 | evaluate_round 4: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:53,353 | server.py:187 | evaluate_round 4 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:07:53,354 | server.py:222 | fit_round 5: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:54,991 | server.py:236 | fit_round 5 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:07:56,590 | server.py:125 | fit progress: (5, 0.3742205798625946, {'accuracy': 0.8134812712669373}, 21.697458499926142)\n",
      "DEBUG flwr 2024-02-01 11:07:56,590 | server.py:173 | evaluate_round 5: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:07:58,147 | server.py:187 | evaluate_round 5 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:07:58,148 | server.py:222 | fit_round 6: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:00,195 | server.py:236 | fit_round 6 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:01,811 | server.py:125 | fit progress: (6, 0.37380558252334595, {'accuracy': 0.8134499788284302}, 26.918699999921955)\n",
      "DEBUG flwr 2024-02-01 11:08:01,812 | server.py:173 | evaluate_round 6: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:03,528 | server.py:187 | evaluate_round 6 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:03,528 | server.py:222 | fit_round 7: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:04,949 | server.py:236 | fit_round 7 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:06,557 | server.py:125 | fit progress: (7, 0.37327754497528076, {'accuracy': 0.8130999803543091}, 31.66446291701868)\n",
      "DEBUG flwr 2024-02-01 11:08:06,557 | server.py:173 | evaluate_round 7: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:07,131 | server.py:187 | evaluate_round 7 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:07,131 | server.py:222 | fit_round 8: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:10,766 | server.py:236 | fit_round 8 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:12,381 | server.py:125 | fit progress: (8, 0.3731796443462372, {'accuracy': 0.8135812282562256}, 37.48851795797236)\n",
      "DEBUG flwr 2024-02-01 11:08:12,381 | server.py:173 | evaluate_round 8: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:13,371 | server.py:187 | evaluate_round 8 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:13,372 | server.py:222 | fit_round 9: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:14,860 | server.py:236 | fit_round 9 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:16,516 | server.py:125 | fit progress: (9, 0.37280145287513733, {'accuracy': 0.813768744468689}, 41.62374595797155)\n",
      "DEBUG flwr 2024-02-01 11:08:16,517 | server.py:173 | evaluate_round 9: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:17,324 | server.py:187 | evaluate_round 9 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:17,324 | server.py:222 | fit_round 10: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:20,867 | server.py:236 | fit_round 10 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:22,973 | server.py:125 | fit progress: (10, 0.3730611205101013, {'accuracy': 0.8135062456130981}, 48.080547707970254)\n",
      "DEBUG flwr 2024-02-01 11:08:22,973 | server.py:173 | evaluate_round 10: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:23,553 | server.py:187 | evaluate_round 10 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:23,554 | server.py:222 | fit_round 11: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:24,984 | server.py:236 | fit_round 11 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:26,708 | server.py:125 | fit progress: (11, 0.37266772985458374, {'accuracy': 0.8136500120162964}, 51.81585966690909)\n",
      "DEBUG flwr 2024-02-01 11:08:26,709 | server.py:173 | evaluate_round 11: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:27,388 | server.py:187 | evaluate_round 11 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:27,388 | server.py:222 | fit_round 12: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:31,097 | server.py:236 | fit_round 12 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:33,591 | server.py:125 | fit progress: (12, 0.37239301204681396, {'accuracy': 0.8137375116348267}, 58.69846270792186)\n",
      "DEBUG flwr 2024-02-01 11:08:33,591 | server.py:173 | evaluate_round 12: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:34,278 | server.py:187 | evaluate_round 12 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:34,279 | server.py:222 | fit_round 13: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:35,806 | server.py:236 | fit_round 13 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:37,500 | server.py:125 | fit progress: (13, 0.37225422263145447, {'accuracy': 0.8136687278747559}, 62.60797708295286)\n",
      "DEBUG flwr 2024-02-01 11:08:37,501 | server.py:173 | evaluate_round 13: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:38,290 | server.py:187 | evaluate_round 13 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:38,291 | server.py:222 | fit_round 14: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:41,843 | server.py:236 | fit_round 14 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:44,090 | server.py:125 | fit progress: (14, 0.37255963683128357, {'accuracy': 0.8139625191688538}, 69.1978898330126)\n",
      "DEBUG flwr 2024-02-01 11:08:44,091 | server.py:173 | evaluate_round 14: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:44,881 | server.py:187 | evaluate_round 14 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:44,882 | server.py:222 | fit_round 15: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:46,456 | server.py:236 | fit_round 15 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:48,075 | server.py:125 | fit progress: (15, 0.37236806750297546, {'accuracy': 0.8136749863624573}, 73.18266670801677)\n",
      "DEBUG flwr 2024-02-01 11:08:48,075 | server.py:173 | evaluate_round 15: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:48,617 | server.py:187 | evaluate_round 15 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:48,618 | server.py:222 | fit_round 16: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:52,376 | server.py:236 | fit_round 16 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:54,785 | server.py:125 | fit progress: (16, 0.372274249792099, {'accuracy': 0.8137187361717224}, 79.89323987497482)\n",
      "DEBUG flwr 2024-02-01 11:08:54,786 | server.py:173 | evaluate_round 16: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:55,670 | server.py:187 | evaluate_round 16 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:55,670 | server.py:222 | fit_round 17: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:57,135 | server.py:236 | fit_round 17 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:08:58,755 | server.py:125 | fit progress: (17, 0.3720639944076538, {'accuracy': 0.8138625025749207}, 83.86316220799927)\n",
      "DEBUG flwr 2024-02-01 11:08:58,756 | server.py:173 | evaluate_round 17: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:08:59,326 | server.py:187 | evaluate_round 17 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:08:59,327 | server.py:222 | fit_round 18: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:09:03,914 | server.py:236 | fit_round 18 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:09:05,602 | server.py:125 | fit progress: (18, 0.3722741901874542, {'accuracy': 0.8137999773025513}, 90.70991270791274)\n",
      "DEBUG flwr 2024-02-01 11:09:05,602 | server.py:173 | evaluate_round 18: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:09:06,208 | server.py:187 | evaluate_round 18 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:09:06,208 | server.py:222 | fit_round 19: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:09:07,680 | server.py:236 | fit_round 19 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:09:09,333 | server.py:125 | fit progress: (19, 0.3723323345184326, {'accuracy': 0.8139125108718872}, 94.44091987493448)\n",
      "DEBUG flwr 2024-02-01 11:09:09,333 | server.py:173 | evaluate_round 19: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:09:10,004 | server.py:187 | evaluate_round 19 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-02-01 11:09:10,004 | server.py:222 | fit_round 20: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:09:14,556 | server.py:236 | fit_round 20 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:09:16,343 | server.py:125 | fit progress: (20, 0.37246355414390564, {'accuracy': 0.8138187527656555}, 101.45113879197743)\n",
      "DEBUG flwr 2024-02-01 11:09:16,345 | server.py:173 | evaluate_round 20: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-02-01 11:09:17,053 | server.py:187 | evaluate_round 20 received 3 results and 0 failures\n",
      "INFO flwr 2024-02-01 11:09:17,053 | server.py:153 | FL finished in 102.16131295799278\n",
      "INFO flwr 2024-02-01 11:09:17,054 | app.py:226 | app_fit: losses_distributed [(1, 0.6284865140914917), (2, 0.37404270966847736), (3, 0.3710823655128479), (4, 0.36984938383102417), (5, 0.3690445323785146), (6, 0.36858779191970825), (7, 0.36810048421223956), (8, 0.3680325547854106), (9, 0.36773555477460224), (10, 0.36795013149579364), (11, 0.36760706702868146), (12, 0.36739293734232586), (13, 0.3672649065653483), (14, 0.3675874173641205), (15, 0.36735546588897705), (16, 0.3673698604106903), (17, 0.36712029576301575), (18, 0.3673142393430074), (19, 0.3673303922017415), (20, 0.3674176534016927)]\n",
      "INFO flwr 2024-02-01 11:09:17,054 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-02-01 11:09:17,054 | app.py:228 | app_fit: metrics_distributed {'accuracy': [(1, 0.7932251890500387), (2, 0.7889790336290995), (3, 0.8179660240809122), (4, 0.8178613384564718), (5, 0.8177593946456909), (6, 0.8177974025408427), (7, 0.8177868326505026), (8, 0.8179660240809122), (9, 0.8179913759231567), (10, 0.8183324734369913), (11, 0.818240741888682), (12, 0.8179184595743815), (13, 0.8181866804758707), (14, 0.818196435769399), (15, 0.8183529774347941), (16, 0.8178406755129496), (17, 0.8181642691294352), (18, 0.8181697726249695), (19, 0.8180368940035502), (20, 0.8183968861897787)]}\n",
      "INFO flwr 2024-02-01 11:09:17,054 | app.py:229 | app_fit: losses_centralized [(0, 198.40919494628906), (1, 0.642350435256958), (2, 0.37901946902275085), (3, 0.3761957883834839), (4, 0.37506216764450073), (5, 0.3742205798625946), (6, 0.37380558252334595), (7, 0.37327754497528076), (8, 0.3731796443462372), (9, 0.37280145287513733), (10, 0.3730611205101013), (11, 0.37266772985458374), (12, 0.37239301204681396), (13, 0.37225422263145447), (14, 0.37255963683128357), (15, 0.37236806750297546), (16, 0.372274249792099), (17, 0.3720639944076538), (18, 0.3722741901874542), (19, 0.3723323345184326), (20, 0.37246355414390564)]\n",
      "INFO flwr 2024-02-01 11:09:17,054 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.7532437443733215), (1, 0.7923937439918518), (2, 0.788100004196167), (3, 0.8126687407493591), (4, 0.8127187490463257), (5, 0.8134812712669373), (6, 0.8134499788284302), (7, 0.8130999803543091), (8, 0.8135812282562256), (9, 0.813768744468689), (10, 0.8135062456130981), (11, 0.8136500120162964), (12, 0.8137375116348267), (13, 0.8136687278747559), (14, 0.8139625191688538), (15, 0.8136749863624573), (16, 0.8137187361717224), (17, 0.8138625025749207), (18, 0.8137999773025513), (19, 0.8139125108718872), (20, 0.8138187527656555)]}\n"
     ]
    }
   ],
   "source": [
    "# Create FedAvg strategy, considering all clients for training and evaluation\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,\n",
    "    fraction_evaluate=1,\n",
    "    min_fit_clients=NUM_CLIENTS,\n",
    "    min_evaluate_clients=NUM_CLIENTS,  \n",
    "    min_available_clients=NUM_CLIENTS, \n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    evaluate_fn=get_evaluate_fn(global_test_dataset),\n",
    ")\n",
    "\n",
    "client_resources = None\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 0}\n",
    "\n",
    "# Start simulation\n",
    "history_nn = fl.simulation.start_simulation(\n",
    "    client_resources = client_resources,\n",
    "    client_fn=get_client_fn(global_train_datasets_list),\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_FML_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.753244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.792394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.812669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.812719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.813481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.813450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.813100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.813581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.813769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.813506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.813650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.813738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.813669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.813963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.813675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.813719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.813863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.813800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.813913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.813819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round  accuracy\n",
       "0       0  0.753244\n",
       "1       1  0.792394\n",
       "2       2  0.788100\n",
       "3       3  0.812669\n",
       "4       4  0.812719\n",
       "5       5  0.813481\n",
       "6       6  0.813450\n",
       "7       7  0.813100\n",
       "8       8  0.813581\n",
       "9       9  0.813769\n",
       "10     10  0.813506\n",
       "11     11  0.813650\n",
       "12     12  0.813738\n",
       "13     13  0.813669\n",
       "14     14  0.813963\n",
       "15     15  0.813675\n",
       "16     16  0.813719\n",
       "17     17  0.813863\n",
       "18     18  0.813800\n",
       "19     19  0.813913\n",
       "20     20  0.813819"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_value_nn = pd.DataFrame(history_nn.metrics_centralized['accuracy']).rename(columns={0: 'round', 1: 'accuracy'})\n",
    "accuracy_value_nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
