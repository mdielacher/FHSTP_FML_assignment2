{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 09:52:59.893538: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-01 09:53:00.328225: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-01 09:53:00.331929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-01 09:53:02.654857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, confusion_matrix\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility\n",
    "seed_value = 42\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank_a = pd.read_csv('../data/BankA.csv')\n",
    "df_bank_b = pd.read_csv('../data/BankB.csv')\n",
    "df_bank_c = pd.read_csv('../data/BankC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_bank_a, df_bank_b, df_bank_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip all string values from the dataset\n",
    "df = df_all.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Never-worked and Without-pay into one category\n",
    "df['workclass'] = df['workclass'].replace(['Never-worked', 'Without-pay'], 'Not-working')\n",
    "df['workclass'] = df['workclass'].replace(['?', '*'], 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Married-civ-spouse and Married-AF-spouse into one category\n",
    "df['marital-status'] = df['marital-status'].replace(['Married-civ-spouse', 'Married-AF-spouse'], 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace occupation by 4 categories (low, medium, high, unknown)\n",
    "df['occupation'] = df['occupation'].replace(['Exec-managerial', 'Prof-specialty'], 'high')\n",
    "df['occupation'] = df['occupation'].replace(['Armed-Forces', 'Protective-serv', 'Tech-support', 'Sales', 'Craft-repair', 'Transport-moving'], 'medium')\n",
    "df['occupation'] = df['occupation'].replace(['Adm-clerical', 'Machine-op-inspct', 'Farming-fishing', 'Handlers-cleaners', 'Other-service', 'Priv-house-serv'], 'low')\n",
    "df['occupation'] = df['occupation'].replace(['?', '*'], 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Husband and Wife into one category\n",
    "df['relationship'] = df['relationship'].replace(['Husband', 'Wife'], 'Parent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map native-country to continents\n",
    "df['native-country'] = df['native-country'].str.strip()\n",
    "df['native-country'] = df['native-country'].replace(['United-States', 'Puerto-Rico', 'Canada', 'Outlying-US(Guam-USVI-etc)', 'Cuba', 'Jamaica', 'Mexico', 'Dominican-Republic', 'El-Salvador', 'Guatemala', 'Haiti', 'Honduras', 'Nicaragua', 'Trinadad&Tobago', 'Peru', 'Ecuador', 'Columbia', 'Honduras', 'Haiti', 'Guatemala', 'El-Salvador', 'Dominican-Republic', 'Columbia', 'Ecuador', 'Peru', 'Jamaica', 'Mexico', 'Puerto-Rico', 'Cuba', 'Outlying-US(Guam-USVI-etc)', 'Canada', 'United-States'], 'North-America')\n",
    "df['native-country'] = df['native-country'].replace(['Germany', 'England', 'Italy', 'Poland', 'Portugal', 'Ireland', 'France', 'Yugoslavia', 'Scotland', 'Greece', 'Hungary', 'Holand-Netherlands'], 'Europe')\n",
    "df['native-country'] = df['native-country'].replace(['Philippines', 'India', 'China', 'Japan', 'Vietnam', 'Taiwan', 'Iran', 'Thailand', 'Hong', 'Cambodia', 'Laos'], 'Asia')\n",
    "df['native-country'] = df['native-country'].replace(['South', 'Columbia', 'Ecuador', 'Peru'], 'South-America')\n",
    "df['native-country'] = df['native-country'].replace(['Trinadad&Tobago', 'Honduras', 'Haiti', 'Guatemala', 'El-Salvador', 'Dominican-Republic', 'Columbia', 'Ecuador', 'Peru'], 'Central-America')\n",
    "df['native-country'] = df['native-country'].replace(['?', '*'], 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'] = df['education'].replace(['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th'], 'school')\n",
    "df['education'] = df['education'].replace(['Assoc-voc', 'Assoc-acdm', 'Prof-school', 'Some-college'], 'higher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulate capital-diff\n",
    "df['capital-diff'] = df['capital-gain'] - df['capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace(['Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert age in bins of 10 years\n",
    "df['age'] = pd.cut(df['age'], bins=[0, 20, 30, 40, 50, 60, 70, 80, 90, 100], labels=['0-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '>90'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the fnlwgt column\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Drop education-num column\n",
    "df.drop(['educational-num'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the gender column\n",
    "df.drop(['gender'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the race column\n",
    "df.drop('race', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace income by 0 and 1\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: institute\n",
      "institute\n",
      "Bank B    403240\n",
      "Bank A    226164\n",
      "Bank C    170595\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: workclass\n",
      "workclass\n",
      "Private             546342\n",
      "Self-emp-not-inc     66145\n",
      "Local-gov            51137\n",
      "unknown              47431\n",
      "State-gov            34717\n",
      "Self-emp-inc         27715\n",
      "Federal-gov          25879\n",
      "Not-working            633\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: education\n",
      "education\n",
      "HS-grad      258661\n",
      "higher       241834\n",
      "Bachelors    133796\n",
      "school       110209\n",
      "Masters       45697\n",
      "Doctorate      9802\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: marital-status\n",
      "marital-status\n",
      "Married                  368820\n",
      "Never-married            250510\n",
      "Divorced                 110459\n",
      "Widowed                   34203\n",
      "Separated                 25566\n",
      "Married-spouse-absent     10441\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: occupation\n",
      "occupation\n",
      "low        281223\n",
      "medium     259651\n",
      "high       211330\n",
      "unknown     47795\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: relationship\n",
      "relationship\n",
      "Parent            362767\n",
      "Not-in-family     212898\n",
      "Own-child         119123\n",
      "Unmarried          80532\n",
      "Other-relative     24679\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: native-country\n",
      "native-country\n",
      "North-America    753935\n",
      "Asia              14694\n",
      "Unknown           14390\n",
      "Europe            14273\n",
      "South-America      2707\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-gain\n",
      "(-100.0, 16666.5]     792260\n",
      "(83332.5, 99999.0]      4665\n",
      "(16666.5, 33333.0]      3019\n",
      "(33333.0, 49999.5]        55\n",
      "(49999.5, 66666.0]         0\n",
      "(66666.0, 83332.5]         0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-loss\n",
      "(-3.6839999999999997, 613.833]    760671\n",
      "(1841.5, 2455.333]                 25034\n",
      "(1227.667, 1841.5]                 12776\n",
      "(2455.333, 3069.167]                 788\n",
      "(613.833, 1227.667]                  540\n",
      "(3069.167, 3683.0]                   190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: hours-per-week\n",
      "(33.667, 50.0]      555199\n",
      "(17.333, 33.667]    105827\n",
      "(50.0, 66.333]       72075\n",
      "(0.901, 17.333]      44806\n",
      "(66.333, 82.667]     16324\n",
      "(82.667, 99.0]        5768\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: income\n",
      "(-0.002, 0.167]    601449\n",
      "(0.833, 1.0]       198550\n",
      "(0.167, 0.333]          0\n",
      "(0.333, 0.5]            0\n",
      "(0.5, 0.667]            0\n",
      "(0.667, 0.833]          0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-diff\n",
      "(-3786.683, 13597.333]    783776\n",
      "(13597.333, 30877.667]     11477\n",
      "(82718.667, 99999.0]        4665\n",
      "(30877.667, 48158.0]          81\n",
      "(48158.0, 65438.333]           0\n",
      "(65438.333, 82718.667]         0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    " \n",
    "for column in df[categorical_columns].columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(df[column].value_counts())\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "# Print also the numberical columns, categorize them into bins of 6\n",
    "numerical_columns = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "for column in df[numerical_columns].columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(df[column].value_counts(bins=6))\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "categorical_columns = categorical_columns.append(pd.Index(['age']))\n",
    "df = pd.get_dummies(df, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop institutes columns\n",
    "df_all = df.drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_a = df[df['institute_Bank A'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_b = df[df['institute_Bank B'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_c = df[df['institute_Bank C'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_all:    799999\n",
      "Number of rows in df_bank_a: 226164\n",
      "Number of rows in df_bank_b: 403240\n",
      "Number of rows in df_bank_c: 170595\n"
     ]
    }
   ],
   "source": [
    "# number of rows in each dataset\n",
    "print(f\"Number of rows in df_all:    {len(df_all)}\")\n",
    "print(f\"Number of rows in df_bank_a: {len(df_bank_a)}\")\n",
    "print(f\"Number of rows in df_bank_b: {len(df_bank_b)}\")\n",
    "print(f\"Number of rows in df_bank_c: {len(df_bank_c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test set that contains 20% of the data from each bank\n",
    "df_bank_a_test = df_bank_a.sample(frac=0.2, random_state=42)\n",
    "df_bank_b_test = df_bank_b.sample(frac=0.2, random_state=42)\n",
    "df_bank_c_test = df_bank_c.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Create a training set that contains the remaining 80% of the data from each bank\n",
    "df_bank_a_train = df_bank_a.drop(df_bank_a_test.index)\n",
    "df_bank_b_train = df_bank_b.drop(df_bank_b_test.index)\n",
    "df_bank_c_train = df_bank_c.drop(df_bank_c_test.index)\n",
    "\n",
    "# Create a validation set that contains 20% of the data from each bank\n",
    "df_bank_a_val = df_bank_a_train.sample(frac=0.2, random_state=42)\n",
    "df_bank_b_val = df_bank_b_train.sample(frac=0.2, random_state=42)\n",
    "df_bank_c_val = df_bank_c_train.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Create a training set that contains the remaining 80% of the data from each bank\n",
    "df_bank_a_train = df_bank_a_train.drop(df_bank_a_val.index)\n",
    "df_bank_b_train = df_bank_b_train.drop(df_bank_b_val.index)\n",
    "df_bank_c_train = df_bank_c_train.drop(df_bank_c_val.index)\n",
    "\n",
    "# Combine the training sets into one training set\n",
    "df_train = pd.concat([df_bank_a_train, df_bank_b_train, df_bank_c_train])\n",
    "\n",
    "# Combine the test sets into one test set\n",
    "df_test = pd.concat([df_bank_a_test, df_bank_b_test, df_bank_c_test])\n",
    "\n",
    "# Combine the validation sets into one validation set\n",
    "df_val = pd.concat([df_bank_a_val, df_bank_b_val, df_bank_c_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and test sets into X and y\n",
    "X_train = df_train.drop('income', axis=1)\n",
    "y_train = df_train['income']\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test['income']\n",
    "X_val = df_val.drop('income', axis=1)\n",
    "y_val = df_val['income']\n",
    "\n",
    "X_train_bank_a = df_bank_a_train.drop('income', axis=1)\n",
    "y_train_bank_a = df_bank_a_train['income']\n",
    "X_test_bank_a = df_bank_a_test.drop('income', axis=1)\n",
    "y_test_bank_a = df_bank_a_test['income']\n",
    "\n",
    "X_train_bank_b = df_bank_b_train.drop('income', axis=1)\n",
    "y_train_bank_b = df_bank_b_train['income']\n",
    "X_test_bank_b = df_bank_b_test.drop('income', axis=1)\n",
    "y_test_bank_b = df_bank_b_test['income']\n",
    "\n",
    "X_train_bank_c = df_bank_c_train.drop('income', axis=1)\n",
    "y_train_bank_c = df_bank_c_train['income']\n",
    "X_test_bank_c = df_bank_c_test.drop('income', axis=1)\n",
    "y_test_bank_c = df_bank_c_test['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "X_val = np.asarray(X_val).astype(np.float32)\n",
    "y_val = np.asarray(y_val).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(5, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(16, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.5397 - accuracy: 0.7539 - val_loss: 0.5267 - val_accuracy: 0.7519\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.5219 - accuracy: 0.7532 - val_loss: 0.5042 - val_accuracy: 0.7531\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.5013 - accuracy: 0.7549 - val_loss: 0.4934 - val_accuracy: 0.7519\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.4853 - accuracy: 0.7572 - val_loss: 0.4863 - val_accuracy: 0.7529\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.4734 - accuracy: 0.7610 - val_loss: 0.4949 - val_accuracy: 0.7517\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.4609 - accuracy: 0.7657 - val_loss: 0.4401 - val_accuracy: 0.7535\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 13s 3ms/step - loss: 0.4543 - accuracy: 0.7712 - val_loss: 0.4700 - val_accuracy: 0.7518\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 13s 3ms/step - loss: 0.4480 - accuracy: 0.7740 - val_loss: 0.4125 - val_accuracy: 0.7682\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 13s 3ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.4501 - val_accuracy: 0.7513\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.4389 - accuracy: 0.7782 - val_loss: 0.4595 - val_accuracy: 0.7728\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 8s 2ms/step\n",
      "[[115368   5151]\n",
      " [ 30947   8534]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7743875"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FML Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 3 # Bank A, B, C\n",
    "NUM_FML_ROUNDS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"Constructs a simple model architecture suitable for the Dataset.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(128, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(40, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(40, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    tf.random.set_seed(seed_value)\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialClient(fl.client.NumPyClient):\n",
    "    def __init__(self, trainset, valset) -> None:\n",
    "        # Create model\n",
    "        self.model = get_model()\n",
    "        self.trainset = trainset\n",
    "        self.valset = valset\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        tf.random.set_seed(seed_value)\n",
    "        self.model.fit(self.trainset[0], self.trainset[1], epochs=1, batch_size=512, verbose=VERBOSE)\n",
    "        return self.model.get_weights(), len(self.trainset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, acc = self.model.evaluate(self.valset[0], self.valset[1], verbose=VERBOSE)\n",
    "        return loss, len(self.valset), {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_fn(global_train_datasets_list):\n",
    "    \"\"\"Return a function to construct a client.\n",
    "\n",
    "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
    "    the strategy to participate.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> fl.client.Client:\n",
    "        \"\"\"Construct a DiabetesClient with its own dataset partition.\"\"\"\n",
    "\n",
    "        # Extract partition for client with id = cid\n",
    "        X, y = global_train_datasets_list[int(cid)]\n",
    "\n",
    "        # Now let's split it into train (90%) and validation (10%)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=seed_value)\n",
    "\n",
    "        trainset = (X_train, y_train)\n",
    "        valset = (X_val, y_val)\n",
    "\n",
    "        # Create and return client\n",
    "        return FinancialClient(trainset, valset)\n",
    "\n",
    "    return client_fn\n",
    "\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
    "    the client's evaluate() method.\"\"\"\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "\n",
    "def get_evaluate_fn(testset):\n",
    "    \"\"\"Return an evaluation function for server-side (i.e. centralised) evaluation.\"\"\"\n",
    "\n",
    "    # The `evaluate` function will be called after every round by the strategy\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ):\n",
    "        model = get_model()  # Construct the model\n",
    "        model.set_weights(parameters)  # Update model with the latest parameters\n",
    "        loss, accuracy = model.evaluate(testset[0], testset[1], verbose=VERBOSE)\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comine train and validation sets for each bank\n",
    "df_bank_a_train_val = pd.concat([df_bank_a_train, df_bank_a_val])\n",
    "df_bank_b_train_val = pd.concat([df_bank_b_train, df_bank_b_val])\n",
    "df_bank_c_train_val = pd.concat([df_bank_c_train, df_bank_c_val])\n",
    "\n",
    "# Split data into X and y\n",
    "X_train_val_bank_a = df_bank_a_train_val.drop('income', axis=1)\n",
    "y_train_val_bank_a = df_bank_a_train_val['income']\n",
    "\n",
    "X_train_val_bank_b = df_bank_b_train_val.drop('income', axis=1)\n",
    "y_train_val_bank_b = df_bank_b_train_val['income']\n",
    "\n",
    "X_train_val_bank_c = df_bank_c_train_val.drop('income', axis=1)\n",
    "y_train_val_bank_c = df_bank_c_train_val['income']\n",
    "\n",
    "X_train_val_bank_a = np.asarray(X_train_val_bank_a).astype(np.float32)\n",
    "y_train_val_bank_a = np.asarray(y_train_val_bank_a).astype(np.float32)\n",
    "\n",
    "X_train_val_bank_b = np.asarray(X_train_val_bank_b).astype(np.float32)\n",
    "y_train_val_bank_b = np.asarray(y_train_val_bank_b).astype(np.float32)\n",
    "\n",
    "X_train_val_bank_c = np.asarray(X_train_val_bank_c).astype(np.float32)\n",
    "y_train_val_bank_c = np.asarray(y_train_val_bank_c).astype(np.float32)\n",
    "\n",
    "# Create a list of datasets for each bank\n",
    "global_train_datasets_list = [\n",
    "    (X_train_val_bank_a, y_train_val_bank_a),\n",
    "    (X_train_val_bank_b, y_train_val_bank_b),\n",
    "    (X_train_val_bank_c, y_train_val_bank_c),\n",
    "]\n",
    "\n",
    "# Create a test set\n",
    "df_test = pd.concat([df_bank_a_test, df_bank_b_test, df_bank_c_test])\n",
    "\n",
    "# Split data into X and y\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test['income']\n",
    "\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "global_test_dataset = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-01-31 18:32:53,915 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
      "2024-01-31 18:32:56,318\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-01-31 18:32:58,380 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:172.29.180.9': 1.0, 'CPU': 8.0, 'memory': 2588265678.0, 'object_store_memory': 1294132838.0}\n",
      "INFO flwr 2024-01-31 18:32:58,382 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-01-31 18:32:58,386 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
      "INFO flwr 2024-01-31 18:32:58,389 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "INFO flwr 2024-01-31 18:32:58,427 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors\n",
      "INFO flwr 2024-01-31 18:32:58,428 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-01-31 18:32:58,432 | server.py:276 | Requesting initial parameters from one random client\n",
      "\u001b[2m\u001b[36m(pid=115785)\u001b[0m 2024-01-31 18:33:03.095075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO flwr 2024-01-31 18:33:06,754 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-01-31 18:33:06,754 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-01-31 18:33:14,950 | server.py:94 | initial parameters (loss, other metrics): 15.82844066619873, {'accuracy': 0.24680624902248383}\n",
      "INFO flwr 2024-01-31 18:33:14,951 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-01-31 18:33:14,952 | server.py:222 | fit_round 1: strategy sampled 3 clients (out of 3)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=115790)\u001b[0m 2024-01-31 18:33:16.098534: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30613356 exceeds 10% of free system memory.\n",
      "\u001b[2m\u001b[36m(pid=115784)\u001b[0m 2024-01-31 18:33:03.427245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "DEBUG flwr 2024-01-31 18:33:21,099 | server.py:236 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2024-01-31 18:33:21,108 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "INFO flwr 2024-01-31 18:33:29,424 | server.py:125 | fit progress: (1, 0.4813481867313385, {'accuracy': 0.7844499945640564}, 14.47218684800464)\n",
      "DEBUG flwr 2024-01-31 18:33:29,425 | server.py:173 | evaluate_round 1: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:33:32,571 | server.py:187 | evaluate_round 1 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:33:32,572 | server.py:222 | fit_round 2: strategy sampled 3 clients (out of 3)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=115789)\u001b[0m 2024-01-31 18:33:32.975129: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30613356 exceeds 10% of free system memory.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-01-31 18:33:37,637 | server.py:236 | fit_round 2 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:33:45,908 | server.py:125 | fit progress: (2, 0.38153594732284546, {'accuracy': 0.789006233215332}, 30.95656736700039)\n",
      "DEBUG flwr 2024-01-31 18:33:45,909 | server.py:173 | evaluate_round 2: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:33:48,455 | server.py:187 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:33:48,456 | server.py:222 | fit_round 3: strategy sampled 3 clients (out of 3)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=115789)\u001b[0m 2024-01-31 18:33:49.238396: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 54582416 exceeds 10% of free system memory.\n",
      "DEBUG flwr 2024-01-31 18:33:53,952 | server.py:236 | fit_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:34:01,888 | server.py:125 | fit progress: (3, 0.37657636404037476, {'accuracy': 0.8107500076293945}, 46.93669316100568)\n",
      "DEBUG flwr 2024-01-31 18:34:01,889 | server.py:173 | evaluate_round 3: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:34:04,572 | server.py:187 | evaluate_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:34:04,574 | server.py:222 | fit_round 4: strategy sampled 3 clients (out of 3)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=115789)\u001b[0m 2024-01-31 18:34:04.848279: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 23091664 exceeds 10% of free system memory.\n",
      "DEBUG flwr 2024-01-31 18:34:09,517 | server.py:236 | fit_round 4 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:34:17,886 | server.py:125 | fit progress: (4, 0.37414294481277466, {'accuracy': 0.8115062713623047}, 62.93468447000487)\n",
      "DEBUG flwr 2024-01-31 18:34:17,887 | server.py:173 | evaluate_round 4: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:34:20,335 | server.py:187 | evaluate_round 4 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:34:20,337 | server.py:222 | fit_round 5: strategy sampled 3 clients (out of 3)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=115789)\u001b[0m 2024-01-31 18:34:20.945035: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 54582416 exceeds 10% of free system memory.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-01-31 18:34:25,832 | server.py:236 | fit_round 5 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:34:34,629 | server.py:125 | fit progress: (5, 0.3733676075935364, {'accuracy': 0.8116000294685364}, 79.67784796200431)\n",
      "DEBUG flwr 2024-01-31 18:34:34,631 | server.py:173 | evaluate_round 5: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:34:37,631 | server.py:187 | evaluate_round 5 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:34:37,633 | server.py:222 | fit_round 6: strategy sampled 3 clients (out of 3)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=115790)\u001b[0m 2024-01-31 18:34:38.468321: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 54582416 exceeds 10% of free system memory.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-01-31 18:34:43,849 | server.py:236 | fit_round 6 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:34:53,571 | server.py:125 | fit progress: (6, 0.37303656339645386, {'accuracy': 0.8115500211715698}, 98.61981473300693)\n",
      "DEBUG flwr 2024-01-31 18:34:53,573 | server.py:173 | evaluate_round 6: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:34:56,047 | server.py:187 | evaluate_round 6 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:34:56,049 | server.py:222 | fit_round 7: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:35:01,512 | server.py:236 | fit_round 7 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:35:09,889 | server.py:125 | fit progress: (7, 0.3726315498352051, {'accuracy': 0.8115562796592712}, 114.9378452230012)\n",
      "DEBUG flwr 2024-01-31 18:35:09,891 | server.py:173 | evaluate_round 7: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:35:12,339 | server.py:187 | evaluate_round 7 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:35:12,341 | server.py:222 | fit_round 8: strategy sampled 3 clients (out of 3)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=115790)\u001b[0m 2024-01-31 18:35:13.088318: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 54582416 exceeds 10% of free system memory.\n",
      "DEBUG flwr 2024-01-31 18:35:17,676 | server.py:236 | fit_round 8 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:35:25,530 | server.py:125 | fit progress: (8, 0.37234988808631897, {'accuracy': 0.8118062615394592}, 130.57886265300476)\n",
      "DEBUG flwr 2024-01-31 18:35:25,532 | server.py:173 | evaluate_round 8: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:35:28,417 | server.py:187 | evaluate_round 8 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:35:28,418 | server.py:222 | fit_round 9: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:35:33,956 | server.py:236 | fit_round 9 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:35:43,126 | server.py:125 | fit progress: (9, 0.3721787631511688, {'accuracy': 0.8120062351226807}, 148.17451518000598)\n",
      "DEBUG flwr 2024-01-31 18:35:43,128 | server.py:173 | evaluate_round 9: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:35:45,776 | server.py:187 | evaluate_round 9 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:35:45,777 | server.py:222 | fit_round 10: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:35:51,068 | server.py:236 | fit_round 10 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:35:59,126 | server.py:125 | fit progress: (10, 0.3720501959323883, {'accuracy': 0.8119875192642212}, 164.17407002100663)\n",
      "DEBUG flwr 2024-01-31 18:35:59,127 | server.py:173 | evaluate_round 10: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:01,896 | server.py:187 | evaluate_round 10 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:36:01,897 | server.py:222 | fit_round 11: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:09,699 | server.py:236 | fit_round 11 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:36:17,728 | server.py:125 | fit progress: (11, 0.3720583915710449, {'accuracy': 0.8118374943733215}, 182.7767698730022)\n",
      "DEBUG flwr 2024-01-31 18:36:17,729 | server.py:173 | evaluate_round 11: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:20,291 | server.py:187 | evaluate_round 11 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:36:20,292 | server.py:222 | fit_round 12: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:25,758 | server.py:236 | fit_round 12 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:36:34,191 | server.py:125 | fit progress: (12, 0.3718473017215729, {'accuracy': 0.8119249939918518}, 199.23963301300682)\n",
      "DEBUG flwr 2024-01-31 18:36:34,192 | server.py:173 | evaluate_round 12: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:36,671 | server.py:187 | evaluate_round 12 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:36:36,672 | server.py:222 | fit_round 13: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:42,445 | server.py:236 | fit_round 13 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:36:51,296 | server.py:125 | fit progress: (13, 0.371700257062912, {'accuracy': 0.8119562268257141}, 216.34465449300478)\n",
      "DEBUG flwr 2024-01-31 18:36:51,297 | server.py:173 | evaluate_round 13: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:53,924 | server.py:187 | evaluate_round 13 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:36:53,925 | server.py:222 | fit_round 14: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:36:59,224 | server.py:236 | fit_round 14 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:37:07,739 | server.py:125 | fit progress: (14, 0.37179073691368103, {'accuracy': 0.8116687536239624}, 232.78753329400206)\n",
      "DEBUG flwr 2024-01-31 18:37:07,740 | server.py:173 | evaluate_round 14: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:37:10,155 | server.py:187 | evaluate_round 14 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:37:10,156 | server.py:222 | fit_round 15: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:37:15,317 | server.py:236 | fit_round 15 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:37:23,228 | server.py:125 | fit progress: (15, 0.37169599533081055, {'accuracy': 0.8119375109672546}, 248.27664372599975)\n",
      "DEBUG flwr 2024-01-31 18:37:23,229 | server.py:173 | evaluate_round 15: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:37:25,645 | server.py:187 | evaluate_round 15 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:37:25,646 | server.py:222 | fit_round 16: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:37:31,752 | server.py:236 | fit_round 16 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:37:40,037 | server.py:125 | fit progress: (16, 0.37178388237953186, {'accuracy': 0.8118875026702881}, 265.08591469500243)\n",
      "DEBUG flwr 2024-01-31 18:37:40,038 | server.py:173 | evaluate_round 16: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:37:42,576 | server.py:187 | evaluate_round 16 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:37:42,577 | server.py:222 | fit_round 17: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:37:47,789 | server.py:236 | fit_round 17 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:37:55,794 | server.py:125 | fit progress: (17, 0.37154388427734375, {'accuracy': 0.8119624853134155}, 280.8428742130054)\n",
      "DEBUG flwr 2024-01-31 18:37:55,796 | server.py:173 | evaluate_round 17: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:37:58,446 | server.py:187 | evaluate_round 17 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:37:58,447 | server.py:222 | fit_round 18: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:38:03,671 | server.py:236 | fit_round 18 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:38:12,096 | server.py:125 | fit progress: (18, 0.3714679777622223, {'accuracy': 0.8119500279426575}, 297.1441421950003)\n",
      "DEBUG flwr 2024-01-31 18:38:12,097 | server.py:173 | evaluate_round 18: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:38:14,719 | server.py:187 | evaluate_round 18 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:38:14,720 | server.py:222 | fit_round 19: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:38:20,184 | server.py:236 | fit_round 19 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:38:28,131 | server.py:125 | fit progress: (19, 0.37125226855278015, {'accuracy': 0.8120874762535095}, 313.1790138760043)\n",
      "DEBUG flwr 2024-01-31 18:38:28,132 | server.py:173 | evaluate_round 19: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:38:30,780 | server.py:187 | evaluate_round 19 received 3 results and 0 failures\n",
      "DEBUG flwr 2024-01-31 18:38:30,781 | server.py:222 | fit_round 20: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:38:36,262 | server.py:236 | fit_round 20 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:38:44,520 | server.py:125 | fit progress: (20, 0.3713931739330292, {'accuracy': 0.8121687769889832}, 329.56809036900086)\n",
      "DEBUG flwr 2024-01-31 18:38:44,521 | server.py:173 | evaluate_round 20: strategy sampled 3 clients (out of 3)\n",
      "DEBUG flwr 2024-01-31 18:38:46,908 | server.py:187 | evaluate_round 20 received 3 results and 0 failures\n",
      "INFO flwr 2024-01-31 18:38:46,908 | server.py:153 | FL finished in 331.95684958100173\n",
      "INFO flwr 2024-01-31 18:38:46,909 | app.py:226 | app_fit: losses_distributed [(1, 0.4733596742153168), (2, 0.37721418341000873), (3, 0.37153281768163043), (4, 0.368949035803477), (5, 0.36815022428830463), (6, 0.3677280942598979), (7, 0.36741804083188373), (8, 0.3672258456548055), (9, 0.3670230805873871), (10, 0.3669576744238536), (11, 0.366894672314326), (12, 0.3667723536491394), (13, 0.3666802942752838), (14, 0.36676639318466187), (15, 0.36671396096547443), (16, 0.36677204569180805), (17, 0.3665733238061269), (18, 0.3665643831094106), (19, 0.36634506781895954), (20, 0.3666144013404846)]\n",
      "INFO flwr 2024-01-31 18:38:46,910 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-01-31 18:38:46,912 | app.py:228 | app_fit: metrics_distributed {'accuracy': [(1, 0.7844858368237814), (2, 0.7903902530670166), (3, 0.8144919077555338), (4, 0.8151882688204447), (5, 0.8148746490478516), (6, 0.8147757848103842), (7, 0.8149720231691996), (8, 0.8150748213132223), (9, 0.8148445884386698), (10, 0.8150861064592997), (11, 0.8146760662396749), (12, 0.8147193392117819), (13, 0.8146315415700277), (14, 0.8146015405654907), (15, 0.8148048718770345), (16, 0.8149001797040304), (17, 0.8150073091189066), (18, 0.8151010870933533), (19, 0.8149862289428711), (20, 0.8150755167007446)]}\n",
      "INFO flwr 2024-01-31 18:38:46,913 | app.py:229 | app_fit: losses_centralized [(0, 15.82844066619873), (1, 0.4813481867313385), (2, 0.38153594732284546), (3, 0.37657636404037476), (4, 0.37414294481277466), (5, 0.3733676075935364), (6, 0.37303656339645386), (7, 0.3726315498352051), (8, 0.37234988808631897), (9, 0.3721787631511688), (10, 0.3720501959323883), (11, 0.3720583915710449), (12, 0.3718473017215729), (13, 0.371700257062912), (14, 0.37179073691368103), (15, 0.37169599533081055), (16, 0.37178388237953186), (17, 0.37154388427734375), (18, 0.3714679777622223), (19, 0.37125226855278015), (20, 0.3713931739330292)]\n",
      "INFO flwr 2024-01-31 18:38:46,915 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.24680624902248383), (1, 0.7844499945640564), (2, 0.789006233215332), (3, 0.8107500076293945), (4, 0.8115062713623047), (5, 0.8116000294685364), (6, 0.8115500211715698), (7, 0.8115562796592712), (8, 0.8118062615394592), (9, 0.8120062351226807), (10, 0.8119875192642212), (11, 0.8118374943733215), (12, 0.8119249939918518), (13, 0.8119562268257141), (14, 0.8116687536239624), (15, 0.8119375109672546), (16, 0.8118875026702881), (17, 0.8119624853134155), (18, 0.8119500279426575), (19, 0.8120874762535095), (20, 0.8121687769889832)]}\n"
     ]
    }
   ],
   "source": [
    "# Create FedAvg strategy, considering all clients for training and evaluation\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,\n",
    "    fraction_evaluate=1,\n",
    "    min_fit_clients=NUM_CLIENTS,\n",
    "    min_evaluate_clients=NUM_CLIENTS,  \n",
    "    min_available_clients=NUM_CLIENTS, \n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    evaluate_fn=get_evaluate_fn(global_test_dataset),\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "history_nn = fl.simulation.start_simulation(\n",
    "    client_fn=get_client_fn(global_train_datasets_list),\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_FML_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.246806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.784450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.789006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.810750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.811506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.811600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.811550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.811556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.811806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.812006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.811988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.811837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.811925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.811956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.811669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.811938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.811888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.811962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.811950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.812087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.812169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round  accuracy\n",
       "0       0  0.246806\n",
       "1       1  0.784450\n",
       "2       2  0.789006\n",
       "3       3  0.810750\n",
       "4       4  0.811506\n",
       "5       5  0.811600\n",
       "6       6  0.811550\n",
       "7       7  0.811556\n",
       "8       8  0.811806\n",
       "9       9  0.812006\n",
       "10     10  0.811988\n",
       "11     11  0.811837\n",
       "12     12  0.811925\n",
       "13     13  0.811956\n",
       "14     14  0.811669\n",
       "15     15  0.811938\n",
       "16     16  0.811888\n",
       "17     17  0.811962\n",
       "18     18  0.811950\n",
       "19     19  0.812087\n",
       "20     20  0.812169"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_value_nn = pd.DataFrame(history_nn.metrics_centralized['accuracy']).rename(columns={0: 'round', 1: 'accuracy'})\n",
    "accuracy_value_nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
