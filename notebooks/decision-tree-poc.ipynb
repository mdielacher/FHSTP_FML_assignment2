{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank_a = pd.read_csv('../data/BankA.csv')\n",
    "df_bank_b = pd.read_csv('../data/BankB.csv')\n",
    "df_bank_c = pd.read_csv('../data/BankC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_bank_a, df_bank_b, df_bank_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip all string values from the dataset\n",
    "df = df_all.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass\n",
       "Private             546342\n",
       "Self-emp-not-inc     66145\n",
       "Local-gov            51137\n",
       "unknown              47431\n",
       "State-gov            34717\n",
       "Self-emp-inc         27715\n",
       "Federal-gov          25879\n",
       "Not-working            633\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine Never-worked and Without-pay into one category\n",
    "df['workclass'] = df['workclass'].replace(['Never-worked', 'Without-pay'], 'Not-working')\n",
    "df['workclass'] = df['workclass'].replace(['?', '*'], 'unknown')\n",
    "df['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marital-status\n",
       "Married                  368820\n",
       "Never-married            250510\n",
       "Divorced                 110459\n",
       "Widowed                   34203\n",
       "Separated                 25566\n",
       "Married-spouse-absent     10441\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine Married-civ-spouse and Married-AF-spouse into one category\n",
    "df['marital-status'] = df['marital-status'].replace(['Married-civ-spouse', 'Married-AF-spouse'], 'Married')\n",
    "df['marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "low        281223\n",
       "medium     259651\n",
       "high       211330\n",
       "unknown     47795\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace occupation by 4 categories (low, medium, high, unknown)\n",
    "df['occupation'] = df['occupation'].replace(['Exec-managerial', 'Prof-specialty'], 'high')\n",
    "df['occupation'] = df['occupation'].replace(['Armed-Forces', 'Protective-serv', 'Tech-support', 'Sales', 'Craft-repair', 'Transport-moving'], 'medium')\n",
    "df['occupation'] = df['occupation'].replace(['Adm-clerical', 'Machine-op-inspct', 'Farming-fishing', 'Handlers-cleaners', 'Other-service', 'Priv-house-serv'], 'low')\n",
    "df['occupation'] = df['occupation'].replace(['?', '*'], 'unknown')\n",
    "df['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relationship\n",
       "Parent            362767\n",
       "Not-in-family     212898\n",
       "Own-child         119123\n",
       "Unmarried          80532\n",
       "Other-relative     24679\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine Husband and Wife into one category\n",
    "df['relationship'] = df['relationship'].replace(['Husband', 'Wife'], 'Parent')\n",
    "df['relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "native-country\n",
       "North-America    753935\n",
       "Asia              14694\n",
       "Unknown           14390\n",
       "Europe            14273\n",
       "South-America      2707\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map native-country to continents\n",
    "df['native-country'] = df['native-country'].str.strip()\n",
    "df['native-country'] = df['native-country'].replace(['United-States', 'Puerto-Rico', 'Canada', 'Outlying-US(Guam-USVI-etc)', 'Cuba', 'Jamaica', 'Mexico', 'Dominican-Republic', 'El-Salvador', 'Guatemala', 'Haiti', 'Honduras', 'Nicaragua', 'Trinadad&Tobago', 'Peru', 'Ecuador', 'Columbia', 'Honduras', 'Haiti', 'Guatemala', 'El-Salvador', 'Dominican-Republic', 'Columbia', 'Ecuador', 'Peru', 'Jamaica', 'Mexico', 'Puerto-Rico', 'Cuba', 'Outlying-US(Guam-USVI-etc)', 'Canada', 'United-States'], 'North-America')\n",
    "df['native-country'] = df['native-country'].replace(['Germany', 'England', 'Italy', 'Poland', 'Portugal', 'Ireland', 'France', 'Yugoslavia', 'Scotland', 'Greece', 'Hungary', 'Holand-Netherlands'], 'Europe')\n",
    "df['native-country'] = df['native-country'].replace(['Philippines', 'India', 'China', 'Japan', 'Vietnam', 'Taiwan', 'Iran', 'Thailand', 'Hong', 'Cambodia', 'Laos'], 'Asia')\n",
    "df['native-country'] = df['native-country'].replace(['South', 'Columbia', 'Ecuador', 'Peru'], 'South-America')\n",
    "df['native-country'] = df['native-country'].replace(['Trinadad&Tobago', 'Honduras', 'Haiti', 'Guatemala', 'El-Salvador', 'Dominican-Republic', 'Columbia', 'Ecuador', 'Peru'], 'Central-America')\n",
    "df['native-country'] = df['native-country'].replace(['?', '*'], 'Unknown')\n",
    "df['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "HS-grad      258661\n",
       "higher       241834\n",
       "Bachelors    133796\n",
       "school       110209\n",
       "Masters       45697\n",
       "Doctorate      9802\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education'] = df['education'].replace(['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th'], 'school')\n",
    "df['education'] = df['education'].replace(['Assoc-voc', 'Assoc-acdm', 'Prof-school', 'Some-college'], 'higher')\n",
    "df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "White    686196\n",
       "Other    113803\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'] = df['race'].replace(['Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'], 'Other')\n",
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "20-30    199748\n",
       "30-40    187599\n",
       "40-50    168168\n",
       "50-60    107704\n",
       "0-20      64609\n",
       "60-70     51995\n",
       "70-80     15668\n",
       "80-90      4508\n",
       "90+           0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'] = pd.cut(df['age'], bins=[0, 20, 30, 40, 50, 60, 70, 80, 90, 100], labels=['0-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90+'])\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the fnlwgt column\n",
    "df.drop(['fnlwgt'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the education column\n",
    "# df.drop(['education'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the capital-gain column\n",
    "# df.drop(['capital-gain'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the capital-loss column\n",
    "# df.drop(['capital-loss'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the gender column\n",
    "df.drop(['gender'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the age column\n",
    "df.drop(['age'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the race column\n",
    "df.drop('race', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "0    601449\n",
       "1    198550\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace income by 0 and 1\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
    "df['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: institute\n",
      "institute\n",
      "Bank B    403240\n",
      "Bank A    226164\n",
      "Bank C    170595\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: workclass\n",
      "workclass\n",
      "Private             546342\n",
      "Self-emp-not-inc     66145\n",
      "Local-gov            51137\n",
      "unknown              47431\n",
      "State-gov            34717\n",
      "Self-emp-inc         27715\n",
      "Federal-gov          25879\n",
      "Not-working            633\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: education\n",
      "education\n",
      "HS-grad      258661\n",
      "higher       241834\n",
      "Bachelors    133796\n",
      "school       110209\n",
      "Masters       45697\n",
      "Doctorate      9802\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: marital-status\n",
      "marital-status\n",
      "Married                  368820\n",
      "Never-married            250510\n",
      "Divorced                 110459\n",
      "Widowed                   34203\n",
      "Separated                 25566\n",
      "Married-spouse-absent     10441\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: occupation\n",
      "occupation\n",
      "low        281223\n",
      "medium     259651\n",
      "high       211330\n",
      "unknown     47795\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: relationship\n",
      "relationship\n",
      "Parent            362767\n",
      "Not-in-family     212898\n",
      "Own-child         119123\n",
      "Unmarried          80532\n",
      "Other-relative     24679\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: native-country\n",
      "native-country\n",
      "North-America    753935\n",
      "Asia              14694\n",
      "Unknown           14390\n",
      "Europe            14273\n",
      "South-America      2707\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: educational-num\n",
      "(8.5, 11.0]     462456\n",
      "(11.0, 13.5]    158326\n",
      "(13.5, 16.0]     69009\n",
      "(3.5, 6.0]       53811\n",
      "(6.0, 8.5]       41887\n",
      "(0.984, 3.5]     14510\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-gain\n",
      "(-100.0, 16666.5]     792260\n",
      "(83332.5, 99999.0]      4665\n",
      "(16666.5, 33333.0]      3019\n",
      "(33333.0, 49999.5]        55\n",
      "(49999.5, 66666.0]         0\n",
      "(66666.0, 83332.5]         0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: capital-loss\n",
      "(-3.6839999999999997, 613.833]    760671\n",
      "(1841.5, 2455.333]                 25034\n",
      "(1227.667, 1841.5]                 12776\n",
      "(2455.333, 3069.167]                 788\n",
      "(613.833, 1227.667]                  540\n",
      "(3069.167, 3683.0]                   190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: hours-per-week\n",
      "(33.667, 50.0]      555199\n",
      "(17.333, 33.667]    105827\n",
      "(50.0, 66.333]       72075\n",
      "(0.901, 17.333]      44806\n",
      "(66.333, 82.667]     16324\n",
      "(82.667, 99.0]        5768\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n",
      "Column: income\n",
      "(-0.002, 0.167]    601449\n",
      "(0.833, 1.0]       198550\n",
      "(0.167, 0.333]          0\n",
      "(0.333, 0.5]            0\n",
      "(0.5, 0.667]            0\n",
      "(0.667, 0.833]          0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    " \n",
    "for column in df[categorical_columns].columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(df[column].value_counts())\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "# Print also the numberical columns, categorize them into bins of 6\n",
    "numerical_columns = df.select_dtypes(include=['int64']).columns\n",
    "\n",
    "for column in df[numerical_columns].columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(df[column].value_counts(bins=6))\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "df = pd.get_dummies(df, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop institutes columns\n",
    "df_all = df.drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_a = df[df['institute_Bank A'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_b = df[df['institute_Bank B'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)\n",
    "df_bank_c = df[df['institute_Bank C'] == 1].drop(['institute_Bank A', 'institute_Bank B', 'institute_Bank C'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_all:    799999\n",
      "Number of rows in df_bank_a: 226164\n",
      "Number of rows in df_bank_b: 403240\n",
      "Number of rows in df_bank_c: 170595\n"
     ]
    }
   ],
   "source": [
    "# number of rows in each dataset\n",
    "print(f\"Number of rows in df_all:    {len(df_all)}\")\n",
    "print(f\"Number of rows in df_bank_a: {len(df_bank_a)}\")\n",
    "print(f\"Number of rows in df_bank_b: {len(df_bank_b)}\")\n",
    "print(f\"Number of rows in df_bank_c: {len(df_bank_c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test set that contains 20% of the data from each bank\n",
    "df_bank_a_test = df_bank_a.sample(frac=0.2, random_state=42)\n",
    "df_bank_b_test = df_bank_b.sample(frac=0.2, random_state=42)\n",
    "df_bank_c_test = df_bank_c.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Create a training set that contains the remaining 80% of the data from each bank\n",
    "df_bank_a_train = df_bank_a.drop(df_bank_a_test.index)\n",
    "df_bank_b_train = df_bank_b.drop(df_bank_b_test.index)\n",
    "df_bank_c_train = df_bank_c.drop(df_bank_c_test.index)\n",
    "\n",
    "# Combine the training sets into one training set\n",
    "df_train = pd.concat([df_bank_a_train, df_bank_b_train, df_bank_c_train])\n",
    "\n",
    "# Combine the test sets into one test set\n",
    "df_test = pd.concat([df_bank_a_test, df_bank_b_test, df_bank_c_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree classifier with grid search to find the best hyperparameters\n",
    "X_train = df_train.drop('income', axis=1)\n",
    "y_train = df_train['income']\n",
    "\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': 14, 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.845206015635376\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features=14,\n",
      "                       min_samples_leaf=12, min_samples_split=8,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Find the best hyperparameters for a decision tree classifier\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "    'min_samples_leaf': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "    'max_features': [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "grid_search = RandomizedSearchCV(estimator=clf, n_iter=30, param_distributions=param_grid, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Train the grid search object to find the best model and the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model with all data from all banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree classifier with the best hyperparameters\n",
    "model = grid_search.best_estimator_\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_global_model = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on each banks test set\n",
    "y_pred_bank_a = model.predict(df_bank_a_test.drop('income', axis=1))\n",
    "accuracy_bank_a_global_model = accuracy_score(df_bank_a_test['income'], y_pred_bank_a)\n",
    "\n",
    "y_pred_bank_b = model.predict(df_bank_b_test.drop('income', axis=1))\n",
    "accuracy_bank_b_global_model = accuracy_score(df_bank_b_test['income'], y_pred_bank_b)\n",
    "\n",
    "y_pred_bank_c = model.predict(df_bank_c_test.drop('income', axis=1))\n",
    "accuracy_bank_c_global_model = accuracy_score(df_bank_c_test['income'], y_pred_bank_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train three models, one for each bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on Bank A data\n",
    "X_train_bank_a = df_bank_a_train.drop('income', axis=1)\n",
    "y_train_bank_a = df_bank_a_train['income']\n",
    "\n",
    "X_test_bank_a = df_bank_a_test.drop('income', axis=1)\n",
    "y_test_bank_a = df_bank_a_test['income']\n",
    "\n",
    "model_bank_a = grid_search.best_estimator_\n",
    "model_bank_a.fit(X_train_bank_a, y_train_bank_a)\n",
    "\n",
    "# Train model on Bank B data\n",
    "X_train_bank_b = df_bank_b_train.drop('income', axis=1)\n",
    "y_train_bank_b = df_bank_b_train['income']\n",
    "\n",
    "X_test_bank_b = df_bank_b_test.drop('income', axis=1)\n",
    "y_test_bank_b = df_bank_b_test['income']\n",
    "\n",
    "model_bank_b = grid_search.best_estimator_\n",
    "model_bank_b.fit(X_train_bank_b, y_train_bank_b)\n",
    "\n",
    "# Train model on Bank C data\n",
    "X_train_bank_c = df_bank_c_train.drop('income', axis=1)\n",
    "y_train_bank_c = df_bank_c_train['income']\n",
    "\n",
    "X_test_bank_c = df_bank_c_test.drop('income', axis=1)\n",
    "y_test_bank_c = df_bank_c_test['income']\n",
    "\n",
    "model_bank_c = grid_search.best_estimator_\n",
    "model_bank_c.fit(X_train_bank_c, y_train_bank_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model on their own test set\n",
    "y_pred_bank_a = model_bank_a.predict(X_test_bank_a)\n",
    "accuracy_bank_a_local_model = accuracy_score(y_test_bank_a, y_pred_bank_a)\n",
    "\n",
    "y_pred_bank_b = model_bank_b.predict(X_test_bank_b)\n",
    "accuracy_bank_b_local_model = accuracy_score(y_test_bank_b, y_pred_bank_b)\n",
    "\n",
    "y_pred_bank_c = model_bank_c.predict(X_test_bank_c)\n",
    "accuracy_bank_c_local_model = accuracy_score(y_test_bank_c, y_pred_bank_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "\n",
      "global model, global testset:  0.8546\n",
      "\n",
      "global model, bank A testset:  0.8232\n",
      "global model, bank B testset:  0.8571\n",
      "global model, bank C testset:  0.8901\n",
      "\n",
      "bank A model, bank A testset:  0.8187\n",
      "bank B model, bank B testset:  0.854\n",
      "bank C model, bank C testset:  0.8871\n"
     ]
    }
   ],
   "source": [
    "# Compare the accuracies of the models\n",
    "\n",
    "print(\"Accuracies:\")\n",
    "print()\n",
    "print(\"global model, global testset: \", round(accuracy_global_model, 4))\n",
    "print()\n",
    "print(\"global model, bank A testset: \", round(accuracy_bank_a_global_model, 4))\n",
    "print(\"global model, bank B testset: \", round(accuracy_bank_b_global_model, 4))\n",
    "print(\"global model, bank C testset: \", round(accuracy_bank_c_global_model, 4))\n",
    "print()\n",
    "print(\"bank A model, bank A testset: \", round(accuracy_bank_a_local_model, 4))\n",
    "print(\"bank B model, bank B testset: \", round(accuracy_bank_b_local_model, 4))\n",
    "print(\"bank C model, bank C testset: \", round(accuracy_bank_c_local_model, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erkenntnisse:  \n",
    "1) \"sensible\" Daten 'gender', 'age', 'race' kann man weglassen, und trotzdem gute Modelle (> 80% Accuracy) trainieren\n",
    "  \n",
    "2) Der Accuracy-Vergleich zeigt, dass die Modelle für die einzelnen Banken minimal besser sind als das Modell für alle Banken zusammen. Da sie aber nur MINIMAL besser sind, deutet das darauf hin, dass der Aufwand von Federated Learning sich nicht lohnt. Jede Bank sollte ihr eigenes Modell trainieren, denn die Modellaggregation mit Modelle anderer Banken würde wahrscheinlich die Performance nur minimal verbessern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
